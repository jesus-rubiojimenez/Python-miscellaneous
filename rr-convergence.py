# Precision convergence in scale-invariant thermometry 
#
# Dr Jes√∫s Rubio
# University of Exeter
# J.Rubio-Jimenez@exeter.ac.uk
#
# Data generated by PhD student Jonas Glatthard
#
# Created: Feb 2022
# Modified: --

import numpy as np
from scipy import special
import matplotlib.pyplot as plt

# Data (change accordingly)
mu_fit = np.loadtxt("rr-convergenceAdata.txt", dtype=float, delimiter=',')
err_fit = np.loadtxt("rr-convergenceBdata.txt", dtype=float, delimiter=',')
mu_bayes = np.loadtxt("rr-convergenceCdata.txt", dtype=float, delimiter=',')
err_bayes = np.loadtxt("rr-convergenceDdata.txt", dtype=float, delimiter=',')

# Noise-to-signal ratio vs number of data
plt.figure(1)
plt.loglog(mu_fit, err_fit, label = "Least-squares")
plt.loglog(mu_bayes, err_bayes, label = "Single-shot optimal Bayes")

plt.xlabel("Number of data")
plt.ylabel("Noise-to-signal ratio")

ax = plt.gca()
ax.set_xlim([np.max( [np.min(mu_fit),np.min(mu_bayes)] ), np.min( [np.max(mu_fit),np.max(mu_bayes)])] )

plt.legend()
plt.grid(True, which="both")

# Speed convergence
slope_fit = np.diff( np.log(err_fit) ) / np.diff( np.log(mu_fit) )
mu_slope_fit = np.delete(mu_fit, 0)
threshold_err_fit = np.abs( slope_fit + 1 ) # mathematically: |[slope - (-1)]/(-1)|

slope_bayes = np.diff( np.log(err_bayes) ) / np.diff( np.log(mu_bayes) )
mu_slope_bayes = np.delete(mu_bayes, 0)
threshold_err_bayes = np.abs( slope_bayes + 1 ) 

mu_threshold = np.linspace( np.min( [np.min(mu_fit),np.min(mu_bayes)] ), np.max( [np.max(mu_fit),np.max(mu_bayes)] ), 10)
threshold = np.ones( np.size(mu_threshold) ) * 0.25

plt.figure(2)
plt.plot(mu_slope_fit,threshold_err_fit, '.', label = "Least-squares")
plt.plot(mu_slope_bayes,threshold_err_bayes, '.', label = "Single-shot optimal Bayes")
plt.plot(mu_threshold,threshold, label = "Threshold")

plt.xlabel("Number of data")
plt.ylabel("log-slope relative error")

plt.legend()
plt.grid(True, which="both")

# Show both plots
plt.show()
